[
  {
    "path": "posts/2021-05-23-bromans-socks/",
    "title": "A Fully Bayesian Analysis of Broman's Socks",
    "description": "When Karl Broman tweeted about his laundry he likely didn't imagine that people would still be estimating how many socks he washed 7 years later. In this post, my willingness to derive some exact formulae will enable a fully Bayesian, sampling free, approach to laundry quantification.",
    "author": [],
    "date": "2021-05-22",
    "categories": [
      "Bayesian",
      "Discrete Probability"
    ],
    "contents": "\n\nContents\nAssumptions\nBååth’s Model\nStopping Time Model\n\n\nThat the 1st 11 socks in the laundry are each distinct suggests there are a lot more socks. pic.twitter.com/EGSo9P6rw7— Karl Broman (@kwbroman) October 17, 2014\n\n\nI belatedly found my way to the puzzle of estimating exactly how many socks Karl Broman washed through Rasmus Bååth’s excellent blog post, which uses the problem to illustrate Approximate Bayesian Computation1.\nRasmus wraps-up the post by presenting three potential criticisms of his analysis, of which one is Why use approximate Bayesian computation at all? I’ll take up his challenge and derive an explicit formula for the likelihood function, and carry out a Bayesian analysis without the need for sampling methods.\nI’ll also propose an alternative model to take into account my personal further belief that the Tweet was made after the 11th sock, knowing that the twelfth sock was going to break the run of distinct socks!\nAssumptions\nThis post makes some assumptions about you: that you’re interested in, and have some experience with, statistics and discrete probability.\nI’ll assume that you’re familiar that the specification of a Bayesian statistics: a model (the likelihood) that describes our understanding of how some data is generated, is combined with some initial assumptions about plausible parameter values (prior distributions) and combining these with observed data we can update our beliefs and draw conclusions (from posterior distributions).\nTo define the likelihood for this problem we’ll need some common constructs from discrete probability/combinatorics: e.g. understanding of factorials, and binomial coefficients.\nBååth’s Model\nOur aim is to estimate the total number of socks that Karl Broman washed on (or around) the 17th October 2014, given that the first 11 drawn from the machine were distinct. I’ll use the following notation throughout:\n\nI use the convention that data is denoted by letters from the Roman alphabet, whilst unknown parameters use the Greek alphabet.\n\\[\n\\begin{align*} \\bf{\\text{Data}}\\\\\nd & = \\text{No. successive distinct socks observed before Tweeting}\\\\\n\\\\\n\\bf{\\text{Parameters}}\\\\\n\\rho & = \\text{No. pairs of socks in the wash}\\\\\n\\sigma & = \\text{No. singleton socks in the wash} \\\\\n\\end{align*}\n\\]\nFor the specific case of the Tweet we have \\(d = 11\\).\nUsing two parameters \\(\\rho\\) and \\(\\sigma\\) allows us to handle the scenario that whilst most socks come in pairs, in some households stray singleton socks are not uncommon. We do however assume socks don’t come in multiples of more than two (excluding the not-uncommon scenario in which two pairs of identical socks are washed).\nThe likelihood, \\(L(d|\\rho,\\sigma)\\), describes how the unknown parameters generate the obsered data: Assuming there were \\(\\rho\\) pairs of socks and \\(\\sigma\\) singletons how likely is it that the first \\(d\\) socks are all distinct?\nAs a warm up for deriving a complete formula, let’s consider some of the edge cases. In particular the formula won’t make sense for values of \\(d > 2\\rho + \\sigma\\) as that means that more socks have been observed than were washed. So in that case the likelihood is 0. We can actually do better than that: there’s a total of \\(\\rho + \\sigma\\) different designs of socks in the wash, which means that at it would be impossible for \\(d > \\rho + \\sigma\\), so again the likelihood would be \\(0\\).\nWith the edge cases handled, let’s look at the formula for the interesting scenario when \\(1 \\leq d \\leq \\rho + \\sigma\\).\n\n\nLikelihood \\[\nL(\\rho,\\sigma|d) = \n\\binom{2\\rho + \\sigma}{d}^{-1} \\sum_{j=0}^{\\sigma} 2^{d-j} \\binom{\\sigma}{j} \\binom{\\rho}{d-j}\n\\]\n\n\nLikelihood and Examples \\[\nL(\\rho,\\sigma|d) = \n\\binom{2\\rho + \\sigma}{d}^{-1} \\sum_{j=0}^{\\sigma} 2^{d-j} \\binom{\\sigma}{j} \\binom{\\rho}{d-j}\n\\]\nAs a soft check that the formula above is correct, let’s take a look at some specific cases.\nExample: \\(\\bf{\\rho = 1, \\, \\sigma = 1, \\,d = 2}\\).\nThis is the smallest non-trial scenario, and we can check this easily by hand. If we denote the socks by {S,P1,P2}, there are three ways to choose two of them: {S,P1}, {S,P2} and {P1,P2}. In two of the scenarios the socks are distinct, so the likelihood is 2/3.\nPlugging the parameters/data into the formula above: \\[\n\\begin{align}\nL(2,1|2) & =   \\binom{3}{2}^{-1} \\left\\{ 2^2 \\binom{1}{0}\\binom{1}{2} + 2^1 \\binom{1}{1}\\binom{1}{1}\\right\\} = 3^{-1}\\left(0 + 2\\right)  = \\frac23\n\\end{align}\n\\]\nExample: \\(\\bf{\\rho=3,\\,\\sigma=4, \\, d = 4}\\)\nWhilst this example doesn’t sound much more complex, crunching numbers directly would be pretty tedious (admittedly, tricky) as the denominator of the likelihood formula suggests there are 210 scenarios to check.\nEvaluating the formula for these parameters indicates the likelihood is 129/210 ~ 0.614.\nWe can quickly validate this by simulating drawing four socks from 3 pairs and 4 singletons, and calculating the proportion of the draws that produced distinct socks.\n\n\nset.seed(1414214)\n\nrho <- 3\nsigma <- 4\nd <- 4\n\n# vector of all the socks\nall_socks <- c(rep(paste0(\"P\",1:rho), 2), paste0(\"S\", 1:sigma))\n\n# a function to sample d socks without replacement from all_socks, and return\n# 1 if all socks are distinct, and 0 otherwise\nsample_socks <- function(all_socks, d){\n  sock_sample <- sample(x = all_socks, size = d, replace = FALSE)\n  return( 1 * (length(sock_sample) == length(unique(sock_sample))) )\n}\n\n# draw samples \ndraws <- tibble(draw = map_dbl(1:1e05, ~sample_socks(all_socks, d)))\n\n\n\n\nSummary\n\nNo. Draws\n100,000\nNo. All Distinct\n61,360\nProb. All Distinct\n0.614\n\n\n\nLikelihood and Proof\n\\[\nL(\\rho,\\sigma|d) = \n\\binom{2\\rho + \\sigma}{d}^{-1} \\sum_{j=0}^{\\sigma} 2^{d-j} \\binom{\\sigma}{j} \\binom{\\rho}{d-j}\n\\]\nIn words, the likelihood is given by the following fraction\n\\[\n\\frac{\\text{No. ways to choose d }{\\bf{distinct}}\\text{ socks from $\\rho$ pairs and $\\sigma$ singletons.}}{\\text{No. ways to choose d socks from  $\\rho$ pairs and $\\sigma$ singletons.}} \n\\]\nStarting with the denominator, this is none other than the total number of ways to choose \\(d\\) objects without replacement from a total of \\(2 \\rho + \\sigma\\) (the factor of two is because \\(\\rho\\) pairs of socks equates to \\(2 \\rho\\) individual socks). That is given by the binomial coefficient \\(\\binom{2\\rho + \\sigma}{d}\\), and explains the leading term in the likelihood formula above.\nTurning to the numerator, I’ll break this down by conditioning on the number of singleton socks. I.e. we’ll count\n\\[\\text{No. of ways to choose $d$ distinct socks, given that $j$ of them are singletons.}\\]\nStarting with the sigletons, there are \\(\\binom{\\sigma}{j}\\) ways to choose exactly \\(j\\) of these. The remaining \\(d-j\\) socks need to come from the pairs, there are \\(\\rho\\) distinct socks that form \\(2\\rho\\) pairs, so there are \\(\\binom{\\rho}{d-j}\\) ways to choose the type of socks. But then for each of these \\(d-j\\) socks we need an additional factor of 2 as we could have chosen between two (left, and right?) socks. Bringing this together, we have:\n\\[2^{d-j}\\binom{\\rho}{d-j}\\binom{\\sigma}{j}.\\]\nThe full formula for numerator, and then the likelihood, follows by summing over the possible values of \\(j = 0,\\ldots,\\sigma\\).\nFor a similar proof, I previously posted an answer to a question on Cross Validated with a slightly different sock related problem.\n\n\nDeriving the Likelihood\nFactored Prior\nBååth’s prior\nStopping Time Model\n\nBååth’s blog post is a great starting point to learn more, but in short: Unlike standard Bayesian approaches, ABC doesn’t require you to write a formula for the likelihood of your model. Instead you describe a sampling procedure that matches the intended distribution. Combining this with samples from a prior distribution enables an acceptance/rejection algorithm which generates samples from the posterior distribution.↩\n",
    "preview": {},
    "last_modified": "2021-06-06T16:03:38+01:00",
    "input_file": "bromans-socks.utf8.md"
  }
]
